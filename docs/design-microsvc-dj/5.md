# 5.从整体到微服务

现在，我们已经了解了我们在服务中的目标是什么，以及我们如何将它们相互联系起来，是时候让我们更仔细地了解实际技术了，这将有助于我们从单一应用迁移到微服务架构。请注意，这里描述的技术不是灵丹妙药，您肯定需要根据自己的使用情况对它们进行修改，但是，经验表明，这些通用方法为成功的迁移提供了一个极好的起点。请记住，本章中描述的一些步骤是并行的，所以如果有更多的人来帮助你，那么可以加快一点速度。

## 开始之前

到目前为止，您可能已经理解了将您的单片系统迁移到微服务并不只是在公园里散步。将会有严重的人力和财力成本。甚至估计交付给你的涉众也可能是一个巨大的困难(至少在开始的时候)，所以让我们来看看你需要计算的基本成本。

### 人力成本

自然，我们谈论的主要是重构代码库的成本。在项目的早期阶段，您将需要比迁移多个组件时多得多的努力。一开始对你的估计要非常保守，在你准备好工具之后，对你自己和你的团队要更严格一点，我们将在第 [5](5.html) 章和稍后的第 [6](6.html) 章中讨论。

根据我的经验，有两个领域的迁移可能会非常困难，并且可能会显著增加您的迁移的编码成本:

1.  运营相关——当迁移到一种新的架构类型时，如何部署和扩展您的新服务始终是一个关键且有分歧的问题。monolith 的部署可能是一个人运行几个脚本将数据同步到远程服务器，然后重新启动应用，监控(当您如此大规模地改变您的基础架构时，这是一个非常重要的方面)可能是在同一条船上。当您转向微服务时，从长远来看，这可能不会奏效。至少，您需要收集这些可执行文件，并以一种可用的方式组织它们，以便公司中的其他人也可以访问它们。我们将在下一章讨论更多与操作相关的主题。

2.  代码相关——你知道什么时候代码像一碗意大利面条一样凌乱，而不是像一片切片的比萨饼一样整齐有序吗？在一个不断推进交付的高速环境中，保持代码库的整洁是一个巨大的挑战。当您想要迁移时，混乱的代码可能是另一个巨大的成本。

根据您的公司和单一应用的规模，最好有一个专门的团队来为其他团队处理工具、文档、指南和最佳实践，这些团队拥有组件迁移的领域知识。如果你和数百名工程师一起操作数百万行代码，这几乎是必须的。如果你的规模稍小，这可能是一个方便。

当一个关键组件由于弹性或其他问题需要迁移时，一些公司喜欢实施应急或“老虎”团队。这可能是将大量软件转移到不同系统的好方法，但是，强烈建议关注代码的移交，并在迁移和维护团队之间实施密集的知识共享会议。

现在，让我们看看我们需要实施的硬件和基础架构的成本。

### 基础设施成本

转移到微服务可能会有另一个昂贵的影响，即拥有足够的机器来运行新系统(以及一段时间内旧系统)的成本。这到底是什么意思？让我们考虑以下场景:

我们的 tizza 应用运行在两个 10 核机器上，内存为 128。在迁移规划期间，我们已经确定了 6 个系统，我们可以在逻辑上将应用分成 6 个系统。现在，让我们来计算一下:

根据系统的负载，我们需要单核或双核机器来提供新服务。处理认证等的系统可能需要两个内核和 8gb 的 ram，而披萨元数据存储可能只需要一个内核和 4gb 的 RAM。我们可以将整个集群的 CPU 数量平均为 8，总内存成本为 32gb。因为，我们曾经用 2 台机器来处理 monolith，我们也应该提高这里的数字，我们毕竟不想降低弹性。

当您试图将您的系统缩减为更小但更高效的部分时，缩小您的集群规模并低估安全运行您的软件所需的原始功率是一种非常人性化的反应。在创建新的微服务器时，我喜欢遵循的一般经验法则是在不同的(虚拟或物理)机器上运行服务的 3 个副本，以实现高可用性。

对于自信的人来说，有了优秀的云提供商、超轻量级的应用和配置良好的自动伸缩系统，就可以消除上述说法。

### 注意

自动扩展是指定义关于您希望在集群中运行的服务器数量的规则。该规则可以是内存或 CPU 使用量、集群的实时连接数、一天中的时间或云提供商可能允许您使用的其他值的函数。

正如您所看到的，我们将系统中的内核总数从 20 个增加到了 24 个，内存保持在 128 左右，总计为 96 个。您将很快注意到，在现实生活环境中，这些数字往往会比预期增长得更快，并且取决于您的提供商，这可能会给您的业务带来毁灭性的成本。

我的建议是，为了安全起见，在开始的时候过犹不及，并不时地重新审视你的应用，以确保硬件不会对软件造成过度破坏。

### 我打了电话，接下来呢？

到目前为止，在阅读本书时，你脑海中出现的最大问题可能是如何说服你的公司，这对他们来说是一项值得的投资，而不仅仅是一个有趣的重构。这是一场旷日持久的辩论，没有灵丹妙药。我会试着给你一些建议，这样你就可以开始了:

*   作为一等项目公民的技术债务:通常人们认为这种类型的变化将需要大项目，其中多人以宏大的规模合作。从本章你会看到，事实并非如此。我能给出的第一个建议是将技术债务和重构转移到你需要交付给公司的特性项目中。确保你在这件事上是透明和合理的，这样你将来也可以这样做。此外，如果你收到一个“不”,那也没关系，只是要坚持下去，这都是关于谈话的。将与技术债务相关的任务放入特性项目中，可以使工程师在这两个方面都更有效率。上下文切换更少，使得特性开发和技术债务工作更有效。工程师们也会更开心，因为他们会把更高质量的工作抛在身后。

*   衡量你的结果:如果你能够在这里或那里进行一些重构，向你的同事展示使用你的新数据库界面有多容易，或者用你提取的功能交付新功能有多快，并确保告诉你的产品所有者或经理。如果你有指标来证明你的工作是值得的，那就更好了。这些指标通常很难找到和提出，其中一些可能与应用速度有关，一些可能与交付速度有关(例如，由于我们在服务中进行了这种和这种技术更改，新功能发布的速度有多快)，甚至是发给您团队的 bug 单的数量。

*   坦诚:确保你衡量了成本并向所有利益相关者解释了成本，而且你诚实地做到了。这将是一个大项目，没有必要让它看起来很小。人们确实需要理解，特性开发将会放缓一段时间，并且将来围绕它的过程会有所不同。

*   有时候没有也没关系:完全有可能你的公司还没有准备好像这样的大规模迁移。在这种情况下，确保你和你的公司尽可能成功，这样你就可以在不久的将来遇到弹性问题。在介绍性章节中，我们已经看到了流应用的灾难场景。像这样的冲击可以导致一家公司改变他们的思维模式，然而，你需要首先在业务上达到那个规模。如果你收到太多的“不”,那么可能是时候重新思考你自己的范围了，把它缩小到你能做到的最小范围，向公司展示这个过程是什么样的，它的价值是什么。

正如你所看到的，从很多方面来说，打这样的电话对一家公司来说是非常困难的。最好的策略通常是保持耐心，把你的挫折抛在脑后，使用你从本书中学到的重构技术和工具，它们在未来会派上用场。

既然我们已经了解了任务的成本，那么是时候开始迁移我们的应用了，首先，通过准备数据。

## 数据准备

在我们进入重构应用的有趣部分之前，我们需要确保我们想要传输的数据是可传输的，这意味着它很容易从一个地方复制到另一个地方，并且不会与系统中的其他数据域耦合太多。除此之外，我们需要找到从领域和业务角度看似乎生活在一起的数据集群。

### 域分片

如您所见，我们可以识别出以下共存的数据块:

*   用户相关信息

*   披萨和餐厅信息

*   喜欢和匹配组

*   事件和事件相关集成

领域规定了上述内容，然而，在上述内容的某些部分之间仍然有许多硬耦合。让我们来看看比萨店的模式:

```py
class Pizzeria(models.Model):
    owner = models.ForeignKey(UserProfile, on_delete=models.CASCADE)
    address = models.CharField(max_length=512)
    phone = models.CharField(max_length=40)

```

如您所见，我们在用户配置文件模型的 owner 字段上有一个硬外键规则。您需要做的第一件事是确保这些外键将指向虚拟对象，其中外部对象可以被认为是这样的引用:

```py
class Pizzeria(models.Model):
    owner_user_profile_id = models.PositiveIntegerField()
    address = models.CharField(max_length=512)
    phone = models.CharField(max_length=40)

```

为什么这是有益的？现在，对象之间的耦合性降低了，并且更加基于信任。比萨饼将信任系统，有一个用户具有给定的用户配置文件 id，并可以生活在他们自己的独立环境中。不再有硬编码的数据库规则将比萨饼和用户资料绑定在一起，这非常解放，但同时也非常可怕。

我们失去了什么？

*   级联删除不见了。您需要手动删除链接的对象。

*   Django ORM 提供的一些方便的方法，比如 select_related，不再可用。

自然，您可以(也应该)保持驻留在同一个数据库中的模型之间的耦合，这样您就保留了方便的方法，并为您的查询提供了一些速度和可靠性。

如果您不是数据库专家，这似乎是一项艰巨的任务。然而，你可能记得我们在第 [2](2.html) 章中了解到的一个强大的工具，叫做迁移。您可以非常容易地创建一个新的迁移，用标识符替换外键。清单 [5-1](#PC3) 为比萨店提供了一个范例。

```py
def set_defaults(apps, schema_editor):
    Pizzeria = apps.get_model('pizza', 'pizzeria')
    for pizzeria in Pizzeria.objects.all().iterator():
        pizzeria.owner_user_profile_id = pizzeria.owner.id
        pizzeria.save()

def reverse(apps, schema_editor):
    pass

class Migration(migrations.Migration):

    dependencies = [
        ('pizza', '0002_pizzeria'),
    ]

    operations = [
        migrations.AddField(
            model_name='pizzeria',
            name='owner_user_profile_id',
            field=models.PositiveIntegerField(null=True),
            preserve_default=False,
        ),
        migrations.RunPython(set_defaults, reverse),
        migrations.AlterField(
            model_name='pizzeria',
            name='owner_user_profile_id',
            field=models.PositiveIntegerField(),
        ),
        migrations.RemoveField(
            model_name='pizzeria',
            name='owner',
        ),
    ]

Listing 5-1Example migration from model to id

```

让我们仔细看看这段代码。在我们更改了模型并运行了 **makemigrations** 命令后，系统会提示我们为我们创建的新字段提供一个默认值，这里我们可以给 0，这不会有太大影响。为了确保所有的值都设置正确，我们将以上述方式修改迁移代码。逻辑如下:

1.  我们向表中添加一个名为 **owner_user_profile_id** 的新字段。我们将它设置为可空，因此迁移可以毫无问题地创建它。

2.  我们运行一组 Python 代码，这些代码将相应地为我们设置值:
    1.  **set_defaults** 函数从已经创建的 pizzerias 中获取所有值，并将它们添加到新字段中。正是我们需要的。

    2.  如果我们真的需要，我们可以为这个函数指定一个反函数。现在不需要它。

3.  我们将 **owner_user_profile_id** 字段改为不可空。

4.  我们将永久删除**所有者**字段。

你可以使用上面的模板来迁移几乎所有的文件。对于行数较多的表(即将整个数据库加载到内存中是很危险的)，强烈建议将 set_defaults 函数中的查询改为批量操作。或者，对于非常大的表(我们这里讨论的是数百万个业务关键行)，您可能希望让数据库专家来帮助迁移。

您可能会有这样的预感，如果您运行这个迁移，一切都会崩溃。嗯，这完全是真的。所有 pizzeria 对象上的 owner 字段将从那里开始破坏您代码库中的代码，这可能会引起一些麻烦。理想情况下，您将更改代码库中的所有代码，以使用为获取所有者对象而创建的新字段，然而，有一些方法可以保护我们不被破坏，例如使用 Python 属性，请参见下面的清单 [5-2](#PC4) 。

```py
class Pizzeria(models.Model):
    owner_user_profile_id = models.PositiveIntegerField()
    address = models.CharField(max_length=512)
    phone = models.CharField(max_length=40)

    @property
    def owner(self):
        return UserProfile.objects.get(id=self.owner_user_profile_id)

Listing 5-2Using properties as model fields

```

以上述方式使用属性可以大大加快迁移过程，但是，从长远来看，它可能会导致问题，特别是性能方面的问题，因为我们刚刚从一个非常高效的数据库连接操作转移到另一个要执行的查询。但是，您稍后会注意到，这并不是我们将获得的最大速度提升。让我们看一下迁移的后续步骤，我们将确保新旧系统都可以访问数据。

### 数据库复制

在决定了要迁移应用的哪一部分并相应地修改了数据库之后，就该在数据库级别上建立迁移计划了。也就是说，是时候准备您的新数据库来托管您的模型了。

也许最简单的开始方法是建立主数据库的副本。我们的想法是将所有写入内容拷贝到复制副本，该复制副本将用作只读。不要太担心只为特定的表设置复制，大多数时候这只会带来麻烦和额外的工作。通常更简单的方法是设置一个完整的复制，并在迁移准备就绪时，从新数据库中删除不需要的表。

### 注意

您还可以在两个数据库之间设置主-主复制，但是，这种技术需要大量的数据库专业知识，并且为发布后的错误提供了更多的空间。

根据数据库的大小和类型，复制可能需要几分钟到几天的时间，因此在与您的直线经理和团队沟通时，请确保将这一点添加到您的估计中。首先，您可能想看看 Amazon RDS 是如何进行数据复制的。如果你想更深入地了解这项技术，dev.mysql.com 网站上有关于如何为 MySQL 设置复制的很好的文档，Postgres 维基百科上有关于 Postgres 的文档。

### 测试和覆盖范围

我们已经做了一些准备。现在是时候复制所有代码了…开个玩笑。理想情况下，这是您确保在将代码从一个系统迁移到另一个系统时应用不会中断的地方。

要做到这一点，你可以使用的最有用的工具就是测试。Django 自带内置的测试框架，你可以很容易地测试数据库级别的测试，包括内存数据库，然而，任何单元测试框架都可以完成这项工作，比如**单元测试 2** 、 **pytest** 或 **nose** 。

当谈到如何衡量你在测试方面做得好不好时，许多团队和工程师推荐使用像 **coverage** 这样的工具，用它你可以衡量你在应用中测试过的代码行数。然而，这个度量并不总是测量您的测试的真实价值。建议您覆盖视图和模型的核心业务功能。理想情况下，如果您在运行后端应用时暴露了一些外部通信方法，那么您还可以实现集成测试，测试整个端点或消费者提供的功能。如果你有人员，那么你也可以实施验收测试，这通常是非常高水平的测试，自动机器人点击通过你的网站，检查基本用户流是否成功。这些系统通常非常脆弱，维护起来也很昂贵，但是，在一个关键的 bug 投入生产之前，它们可以作为最后一道防线拯救生命。cucumber 是一个优秀的验收测试框架，你可以在 cucumber.io 上了解更多。

既然我们已经用测试覆盖了代码，是时候开始使用一些工具了，这样我们就可以将代码库从一个地方迁移到另一个地方。

## 移动服务

到目前为止，我们对想要迁移的模型做了一些工作，并准备了一个新的数据库。是时候开始实际迁移代码了。

### 远程模型

在我们能够复制想要在独立系统中运行的代码库部分之前，我们需要确保两个代码库之间的依赖关系是可管理的。到目前为止，我们已经了解到 Django 和 Python 是构建和维护服务的非常灵活的工具，然而，我们也了解到对模型形式的数据有很大的依赖性。考虑清单 [5-3](#PC5) 中的代码片段，我们希望将它迁移到一个单独的服务中:

```py
from pizza.models import Like
from user.models import UserProfile

def get_fullname_and_like_count(user_profile_id):
    user_profile = UserProfile.objects.get(id=user_profile_id)
    full_name = user_profile.first_name + ' ' + user_profile.last_name
    likes = Likes.objects.count()
    return full_name, likes

Listing 5-3Problematic function to extract

```

无论我们想从哪个服务中提取上面的代码，我们都会面临一个两难的境地。函数中存在对模型的交叉引用，这可能很难解决。如果我们想避免数据重复和清理领域，我们需要确保喜欢和用户配置文件不驻留在单独的服务和数据库中。为此，我们可以做一个重构技术，我们称之为远程模型。

远程模型是我在职业生涯中多次遇到的一个概念，它们是真正的救星。这个想法是，如果你的 API 是统一的，你可以很容易地用远程调用替换你的数据库模型调用，在你的代码库中使用简单的搜索和替换(至少在大多数情况下)。参见清单 [5-4](#PC6) 中的远程模型实现示例。

### 注意

我们将看到的代码可能不完全符合您的需求，但它是一个很好的起点，可以让您开始用远程模型思考问题。

```py
import requests
import urllib.parse

from settings import ENTITY_BASE_URL_MAP

class RemoteModel:

    def __init__(self, request, entity, version):
        self.request = request
        self.entity = entity
        self.version = version
        self.url = f'{ENTITY_BASE_URL_MAP.get(entity)}/api/{version}/{entity}'

    def _headers(self, override_headers=None):
        base_headers = {'content-type': 'application/json'}
        override_headers = override_headers or {}
        return {
            **request.META,
            **base_headers,
            **override_headers,
        }

    def _cookies(self, override_cookies=None):
        override_cookies = override_cookies or {}
        return {
            **self.request.COOKIES,
            **override_cookies,
        }

    def get(self, entity_id):
        return requests.get(
            f'{self.url}/{entity_id}',
            headers=self._headers(),
            cookies=self._cookies())

    def filter(self, **conditions):
        params = f'?{urllib.parse.urlencode(conditions)}' if conditions else "
        return requests.get(
            f'{self.url}/{params}',
            headers=self._headers(),
            cookies=self._cookies())

    def delete(self, entity_id):
        return requests.delete(
            f'{self.url}/{entity_id}',
            headers=self._headers(),
            cookies=self._cookies())

    def create(self, entity_id, entity_data):
        return requests.put(
            f'{self.url}/',
            data=json.dumps(entity_data),
            headers=self._headers(),
            cookies=self._cookies())

    def update(self, entity_id, entity_data):
        return requests.post(
            f'{self.url}/{entity_id}'
            data=json.dumps(entity_data),
            headers=self._headers(),
            cookies=self._cookies())

Listing 5-4The basic remote model

```

代码太多了。让我们仔细看看。您可能注意到的第一件事是,**remote model**class’接口公开了 Django 模型和标准的混合，这是我们在探索 REST 框架的过程中建立的。为了简单的重构和熟悉领域，get、filter、delete、create、update 方法公开了一个类似 Django 模型的接口，然而，实现本身包含了很多我们在研究 REST 范例时遇到的词汇。

**ENTITY_BASE_URL_MAP** 是一个方便的映射，您可以在设置文件中创建它来为您正在处理的每个实体指定唯一的 URL 基础。

到目前为止，所有这些都很简单。那么诀窍在哪里呢？您可能已经注意到，在创建远程模型的实例时，请求对象是一个必需的参数。这是为什么？简单地说，我们使用请求对象来传播我们在请求本身中收到的头。这样，如果您使用头或 cookies 进行身份验证，所有内容都将顺利传播。

在此之后，这些模型的使用应该是相当容易的。为了方便起见，您可以根据您的特定需求对 RemoteModel 进行子类化，就像我们在清单 [5-5](#PC7) 中所做的那样:

```py
class RemotePizza(RemoteModel):

    def __init__(self, request):
        super().__init__(request, 'pizza', 'v1')

Listing 5-5Simple remote pizza

```

然后，您可以在视图函数中执行以下操作，如清单 [5-6](#PC8) 所示:

```py
pizza = RemotePizza(request).get(1)
pizzas = RemotePizza(request).filter(title__startswith='Marg')
RemotePizza(request).delete(1)

Listing 5-6Examples of remote pizza usage

```

### 注意

过滤器函数需要在服务器端进行额外的实现，因为 Django REST 框架默认不支持它们。

远程模型的缺点:

*   远程模型可能会很慢——取决于网络、实现、硬件，有时还取决于星的排列，远程模型可能会比它们的数据库对应物慢得多。当您开始在您的体系结构上“链接”远程方法时，通过调用调用其他系统的其他系统的系统，这种缓慢也会升级。

*   它更脆弱——一般来说，远程模型比常规模型脆弱得多。与数据库的连接比通过 HTTP 进行的连接更加健壮和持久。

*   需要彻底检查批量操作和循环——有时在迁移过程中会复制不理想的代码，比方说，通过模型调用数据库的 for 循环变成了通过远程模型的 HTTP 调用。由于第一点，如果我们查询大量的模型，这可能是毁灭性的。

*   没有序列化——如果您使用这个简单的模型，您肯定会失去序列化的能力，这意味着您只会收到一个作为响应返回的 dict，而不一定是您所期望的一个模型或多个模型。这不是一个无法解决的问题，你可以研究一下 Python **dataclass** es 和类似**英安岩**的模块。

远程模型实现过程中出现的另一个好话题是缓存。缓存是一个很难解决的问题，所以我建议您不要在第一次迭代中实现它。我多年来注意到的一个简单而巨大的成功是在您的服务中实现请求级缓存。这意味着，每个远程调用的结果都以某种方式存储在请求中，不需要再次从远程服务中获取。这允许您在一个视图函数中从您的服务对同一个资源进行多个远程模型调用，而不实际使用网络来获取资源。这可以节省大量的网络流量，即使在开始。

让我们看一下练习 5-1、5-2 和 5-3，它们将帮助我们更多地使用远程模型。

### 练习 5-1:服务对服务的远程模型

上面的模型很好地解决了头和 cookie 传播的问题，因此我们可以使用认证方法(如我们在前面章节中看到的会话或认证头)从系统的各个点访问数据。然而，如果我们想在没有用户认证的情况下调用服务时使用不同的令牌，这可能会导致问题。在本练习中，鼓励您为 RemoteModel 设计一个扩展，通过它我们可以正确地分配覆盖身份验证令牌。上面已经有一些代码可供您使用。

### 练习 5-2:远程或非远程

远程模型看起来已经是一个非常强大的工具了，但是我们能让它们更加强大吗？当模型在本地数据库中可用时，尝试扩展 RemoteModel 类，以便能够处理数据库调用。进行这一更改可以让您在未来加快迁移速度。

### 练习 5-3:请求级缓存

我们之前提到过请求级缓存，现在是时候测试我们的 Python 和 Django 知识并实现它了。每次调用远程模型动作时，确保将响应存储在与请求本身相关的缓存中。为此，您可以使用各种缓存库，如 cachetools。

在我们的工具上工作是非常有趣的，是代码迁移的时间。

### 代码迁移

这可能是整个迁移过程中最不激动人心的部分。您需要复制您希望其他系统拥有的代码库。您需要为这些应用创建一个新的 Django 项目，找到设置和实用程序，并复制所有内容。当我处于迁移的这个阶段时，我喜欢遵循以下几个提示:

*   保持简单——在这一点上，不需要太担心服务之间的代码重复(除非您已经有了一些工具来实现这一点)。只要确保您的应用尽快启动并运行即可。无论如何，我们都要删除 monolith 中的代码。

*   遵循领域——就像数据分片一样，领域在这里也是关键。确保您想要移出的模块尽可能与系统隔离。你想要的目标，只是把一个应用从一个代码库复制到另一个代码库。

*   测试是关键——您创建的一些微服务本身就是怪物。例如，您可能有一个支付服务，它有一个内部状态机和对各种支付提供商的多个集成，您已经决定将整个域提取出来。确保您的测试在适当的位置，运行并最终不会中断。手工测试如此庞大的系统几乎是不可能的。如果您遗漏了一些代码或功能，测试也可以帮助您进行迁移。

*   接受你首先会降低速度的事实——迁移需要一段时间是一回事，但是应用通常在生命周期的早期会变得更慢。这是由我们用远程模型检查的上述负面因素造成的。你会注意到，从长远来看，所有者团队会像他们领域中最有知识的工程师一样，很好地维护他们的应用并实现各种速度增强特性。

### 释放；排放；发布

代码被复制，所有的测试都通过了，是时候发布了。

#### 战略

新微服务的首次部署总是有点混乱，并且需要事先就策略和方法进行大量讨论。正如本书中的大多数地方一样，发布过程没有灵丹妙药，但是，有一些方法可以选择，这取决于您的准备、工具和您的团队是否愿意早点醒来。

*先读，后写*——这种策略意味着微服务将首先只以只读模式运行，也就是说其上的流量不会修改它所拥有的数据。这是我最喜欢的策略之一，它允许你同时使用 monolith 和新的微服务来访问数据。如果您选择设置新数据库的读取复制，那么使用新服务提供的读取功能的 API 应该是相当安全的，例如获取 pizza 元数据。这样，您可以确保您的应用在生产环境中运行，并且只有在您确信您的基础架构能够处理它时，才开始在其中写入数据。

*滚动部署* -基本上意味着你将把总流量的一部分发送到新的微服务，而将其余部分留在 monolith 上，缓慢但稳定地让所有流量由新系统处理。借助现代负载平衡器和服务网格，这可以很容易地建立起来。如果您选择创建一个读取副本，这不是一个选项，因为在新的微服务数据库上发生的写入不会在 monolith 的数据库中注册。

*全流量变化*——可能是最容易实现也是恢复最快的。当您确信您的服务工作正常时，您可以将给定 url 上的流量切换到新服务。这个过程应该简单且容易逆转，例如改变网站或文件的配置。

### 注意

当然，我们可以在这里讨论许多其他的发布策略。主要的想法是围绕你所拥有的关于风险、难度和准备时间的选项有一个背景，这样你就可以就你想要如何解决这个问题做出一个有根据的决定。

既然我们已经知道了发布我们的服务应该采用什么样的策略，那么让我们来看看当事情不可避免地发生时，我们该如何应对。

#### 处理停机

根据我的经验，当发布新的微服务时，总会有一些预期的停机时间。好消息是，如果您事先做了几个小的准备步骤，这种停机时间可以最小化:

*   为恢复创建一个剧本——这可能是你能做的最重要的事情。确保你有一个一步一步的指南，让工程师将流量恢复到单一的应用。起初这看起来似乎微不足道，但在实际环境中，事情可能会变得非常糟糕，特别是在关键任务服务中，比如披萨元数据。确保也练习剧本，并让其他团队参与审查。

*   日志记录和监控应该到位——您的日志记录和指标应该到位，并在发布期间得到适当的监控，包括 monolith、新服务和数据库。

*   选择时间和地点——理想情况下，这样的发布应该发生在流量低的时候，你最了解你的应用，所以相应地选择时间。一般来说，周一早上或周六早上是这种迁移的好选择。如果有机会，让所有者团队和平台团队(如果有的话)的人员在现场进行有效的沟通。

*   关于阶段化的实践——许多团队忘记的是，他们的系统通常有一个预生产或阶段化的环境。您可以利用这个空间来练习几次发布，因为这里最好没有真实的客户数据。

*   让公司的其他人知道-这是至关重要的一步，确保公共关系和客户服务团队了解即将进行的维护以及对客户可能产生的影响。他们知道的越多，如果事情变糟，他们就能更有效地沟通。

*   不要忘记数据——确保你也有一个数据回填的计划，因为在一个有问题的版本中，monolith 和 microservice 数据库之间可能会有数据差异。

这里有一个在遭受攻击的情况下恢复 **tizza** 应用的示例剧本。我们的目标是做发布的人不需要考虑任何事情，只需要按照说明去做。

1.  先决条件:
    1.  确保您连接到了 **VPN** 。

    2.  确保您可以访问 [`http://ci.tizza.io`](http://ci.tizza.io) 。

    3.  确保您可以通过 ssh 访问所请求的机器。

    4.  在你的机器上克隆最新的 [`https://github.com/tizza/tizza`](https://github.com/tizza/tizza) 。

2.  在 **#alerts** 频道用 **@here** 宣布你的版本有问题，需要恢复。

3.  参观 [`http://ci.tizza.io/tizza/deploy`](http://ci.tizza.io/pizza/deploy)

4.  选择您想要部署的应用版本，然后点击绿色按钮。

5.  如果部署工具报告失败，请继续。

6.  **ssh** 进入主机，可以使用 **ssh -A <主机 ip >**

7.  运行以下命令:
    1.  **【sudo su-**

    2.  **bash-x ./maintenance/set-application-version . sh<应用版本>**

    3.  **supervisor TL 重启保证-应用粉笔-engine**

8.  如果服务仍然没有响应，请拨打+36123456789

这个剧本非常简单，但是，它为开发人员提供了多种解决方案。它包括一个先决条件部分，因此运行这些命令的开发人员可以确保他们能够完成剧本要求的所有事情。它还包括一个灾难情况解决方案，其中提供了一个电话号码，该号码很可能与该领域中有经验的开发人员相关联。

第二步还有一个针对公司其他部门的沟通计划。这是绝对重要的，因为如果出了什么差错，你公司的其他人也会感兴趣。

我们做到了！应用已经迁移，但是我们还没有完全准备好。最有趣的部分还在后面。让我们谈谈如何确保我们不会留下一个巨大的烂摊子。

### 清除

图表和日志看起来很棒。客户没有抱怨任何新的问题，系统是稳定的。恭喜你，你刚刚发布了一个新的微服务！现在最有趣的事情来了:收拾我们留下的烂摊子。

就像你处理你的厨房一样，确保你不会在旧代码库中留下不需要的东西。您可以慢慢来，事实上，将旧代码保留 2-3 周通常是一个好主意，因此如果有一些问题，您仍然可以使用您创建的行动手册恢复到旧逻辑。

在您的新服务成熟一段时间后，请确保完成以下清理清单:

*   关闭 monolith 和微服务数据库之间的复制——如果您还没有这样做，现在可以关闭两个数据库之间的数据复制。

*   从新服务中删除未使用的表——如果您进行了简单的完整数据库复制，现在可以从微服务的数据库中删除域中不涉及的表。这将释放大量存储空间。

*   从 monolith 中移除不用的代码——移除不用的模块。确保进行一次彻底的清理，利用像 **pycodestyle** 这样的工具来找到可以删除的未使用的代码。

*   从 monolith 中删除未使用的表——现在您已经确定没有代码访问已经迁移到新服务的表，您可以安全地删除它们了。将这些数据存档并存储一段时间也是一个好主意，花费不多。

## 结论

在这一章中，我们学到了很多可以用来加速微服务迁移的小技巧。与此同时，我们的新系统也搞得一团糟。有许多重复的代码，仍然不清楚谁拥有应用的哪些部分。在下一章中，我们将更深入地探讨这一话题，并确保我们不仅能增加我们拥有的服务数量，还能扩展我们的组织和开发，以利用这些系统实现最佳效率。